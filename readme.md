# Learning how to use Apache Airflow

Airflow documentation is found [here](https://airflow.apache.org/).

## What is Airflow
From [YouTube video][1]:
>Airflow is a platform to programmatically author, schedule, and monitor workflows 
, aka directed acyclic graphs (DAGs).

## Use cases
- ETL pipelines
- ML pipelines
    - Scoring/Ranking
    - Recommender systems
    - etc.
- General job scheduling
    - DB backups
    - Scheduled code/config deployment
  
## Relevant blog posts
1. [Getting started with Apache Airflow][2]
2. [Understanding Apache Airflow's key concepts][3]
3. [Airflow tips, tricks and pitfalls][4]
4. [When Airflow isnâ€™t fast enough: Distributed orchestration of multiple small workloads with Celery][6]

## YouTube videos
1. [Building (Better) Data Pipelines with Apache Airflow][1]
2. [PyCon.DE 2017 Tamara Mendt - Modern ETL-ing with Python and Airflow (and Spark)][5] 

<!-- References --> 
[1]: https://www.youtube.com/watch?v=6eNiCLanXJY
[2]: https://towardsdatascience.com/getting-started-with-apache-airflow-df1aa77d7b1b
[3]: https://medium.com/@dustinstansbury/understanding-apache-airflows-key-concepts-a96efed52b1a
[4]: https://caserta.com/data-blog/airflow-tips-tricks-pitfalls/
[5]: https://www.youtube.com/watch?v=tcJhSaowzUI
[6]:  https://medium.com/@manuelmourato25/when-airflow-isnt-fast-enough-distributed-orchestration-of-multiple-small-workloads-with-celery-afb3daebe611
